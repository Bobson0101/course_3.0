{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuY6fEoSoCiA6GlnV5gaX2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Signal Classification"
      ],
      "metadata": {
        "id": "82dhsvRUKofa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "訊號與圖的分類一樣，在preprocess後可使用神經網路做一些AI任務，例如訊號分類、迴歸還有生成等等。\n",
        "\n",
        "這個部分我們用音訊作為訊號的範例，來試著將聲音訊號做分類，包含以下部分:\n",
        "- Audio Data Loader\n",
        "- RNN audio classification\n",
        "- CNN audio classification"
      ],
      "metadata": {
        "id": "5mo7TK6mKrry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "開始之前我們先準備一些內容。\n",
        "\n",
        "我們使用的範例資料集是tensorflow提供的[Mini Speech Commands](https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html)資料集，從官網下載。"
      ],
      "metadata": {
        "id": "R-B1OWAKMDtL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTGJO2yTGgQ_"
      },
      "outputs": [],
      "source": [
        "!wget http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\n",
        "!unzip mini_speech_commands.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import IPython.display as idp # 播音工具\n",
        "import librosa.display as ldp # 畫頻譜圖工具\n",
        "import numpy as np # 輔助運算\n",
        "import matplotlib.pyplot as plt # 輔助畫圖\n",
        "\n",
        "# import model用到的內容\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models"
      ],
      "metadata": {
        "id": "g1m6erWYMR6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio Data Loader"
      ],
      "metadata": {
        "id": "jo_9jVjhRVfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "與前面CNN相同，需要有data loader去對資料做讀取，而tensorflow沒有原生讀音訊的data loader (TF 2.11有，但在Colab上要另外灌TF2.11)，所以這部分要自己寫。"
      ],
      "metadata": {
        "id": "ryzrWNvWRZqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob #拿來列資料夾內容的小套件\n",
        "\n",
        "def find_class(x):\n",
        "    # 根據格式，找到所屬class\n",
        "    return x.strip('/')[-2]\n",
        "\n",
        "def audio_folder_dataset( dataset_path,class_dictionary, sr=22050, duration=None):\n",
        "    # 輸入: \n",
        "    ## dataset_path - 資料夾，內有數個不同class的資料夾，內有.wav檔\n",
        "    ## class_dictionary - dictionary物件，對應每個資料夾的class\n",
        "    ## sr -  讀取的sampling rate\n",
        "    ## duration - 可指定秒數(float32)，不指定則為原檔長度\n",
        "    file_names = []\n",
        "    labels = []\n",
        "    for cls, class_id in class_dictionary.items():\n",
        "        f_list=glob(dataset_path+f'{cls}/*.wav') # 找到該class的所有檔案\n",
        "        file_names.extend(f_list) # 加入列表\n",
        "        labels.extend([class_id]*len(f_list)) # 加入相應labels\n",
        "    print(\"total:\",f\"{len(file_names)} files of {len(class_dictionary)} classes\")\n",
        "    \n",
        "    # 得到所有資料夾名稱\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(file_names) # 轉換成檔名的Dataset物件\n",
        "\n",
        "    label_ds= tf.data.Dataset.from_tensor_slices(labels)\n",
        "\n",
        "    def load_wav(fname):\n",
        "        # 使用指定sampling rate, duration讀檔\n",
        "        # 會從binary格式轉成一般文字再開始做\n",
        "        return librosa.load(fname.numpy(), sr=sr, duration=duration)\n",
        "    def load_file(fname):\n",
        "        # 使用\n",
        "        return tf.py_function(func=load_wav, inp=[fname], Tout=tf.float32)\n",
        "    data_ds=path_ds.map(\n",
        "            load_file,\n",
        "            num_parallel_calls=tf.data.AUTOTUNE,\n",
        "        )\n",
        "    return tf.data.Dataset.zip((data_ds,label_ds))"
      ],
      "metadata": {
        "id": "m3KXFuxQRZD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 準備一些參數輸入進function生成dataset\n",
        "DATASET_PATH='mini_speech_commands/'\n",
        "class_dict={\n",
        "    'down':0,\n",
        "    'go':1,\n",
        "    'left':2,\n",
        "    'no':3,\n",
        "    'right':4,\n",
        "    'stop':5,\n",
        "    'up':6,\n",
        "    'yes':7\n",
        "}\n",
        "afd=audio_folder_dataset(DATASET_PATH,class_dict)"
      ],
      "metadata": {
        "id": "Yow6YjV7eqcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "DATASET_PATH='mini_speech_commands/'\n",
        "file_names=glob(DATASET_PATH+'*/*.wav') # 得到所有資料夾名稱\n",
        "\n",
        "afd=audio_folder_dataset(DATASET_PATH,class_dict) # 生成dataset"
      ],
      "metadata": {
        "id": "6dJq8zgWWD7I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}